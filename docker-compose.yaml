# Docker Compose configuration for Cerebro development and testing
# This setup provides:
# - Elasticsearch single-node cluster (no authentication for easy testing)
# - Original Cerebro (Scala version) for comparison
# - Optional Kibana for additional cluster management
#
# Usage:
#   docker-compose up -d              # Start all services in background
#   docker-compose down               # Stop and remove containers
#   docker-compose down -v            # Stop and remove containers + volumes
#   docker-compose logs -f es01       # View Elasticsearch logs
#   docker-compose logs -f cerebro-original  # View original Cerebro logs
#   docker-compose ps                 # Check container status
#
# Access:
#   Elasticsearch:     http://localhost:9200
#   Original Cerebro:  http://localhost:9000
#   Cerebro Rewrite:   http://localhost:27182 (run backend separately: cargo run)
#   Kibana:            http://localhost:5601 (if enabled)
#
# Note: Run Cerebro rewrite backend separately with `cargo run` in the backend/ directory.
#       The rewrite uses port 27182 (Euler's number - e â‰ˆ 2.7182) by default.
#       Both versions can connect to the same Elasticsearch at http://localhost:9200.

volumes:
  esdata01:
    driver: local
  kibanadata:
    driver: local

networks:
  elastic:
    driver: bridge

services:
  # Elasticsearch single-node cluster
  # Configured without security for easy testing
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: es01
    environment:
      - node.name=es01
      - cluster.name=cerebro-test-cluster
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      # Disable security for testing
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - esdata01:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - elastic
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 30s

  # Original Cerebro (Scala version)
  # Runs on port 9000 for comparison with the rewrite
  # Pre-configured to connect to Elasticsearch
  cerebro-original:
    image: lmenezes/cerebro:latest
    container_name: cerebro-original
    depends_on:
      es01:
        condition: service_healthy
    ports:
      - "9000:9000"
    networks:
      - elastic
    environment:
      - CEREBRO_PORT=9000
    volumes:
      - ./cerebro-config:/opt/cerebro/conf:ro
    command: ["-Dconfig.file=/opt/cerebro/conf/application.conf"]

  # Kibana (optional, for additional cluster management)
  # Uncomment if you want to use Kibana alongside Cerebro
  # kibana:
  #   image: docker.elastic.co/kibana/kibana:8.11.0
  #   container_name: kibana
  #   depends_on:
  #     es01:
  #       condition: service_healthy
  #   environment:
  #     - SERVERNAME=kibana
  #     - ELASTICSEARCH_HOSTS=http://es01:9200
  #   volumes:
  #     - kibanadata:/usr/share/kibana/data
  #   ports:
  #     - "5601:5601"
  #   networks:
  #     - elastic
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 30
  #     start_period: 30s
